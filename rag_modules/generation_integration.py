'''
ç”Ÿäº§é›†æˆæ¨¡å—
'''
import logging
import os 
from langchain_openai import ChatOpenAI
from typing import List
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate,PromptTemplate
from langchain_core.output_parsers import StrOutputParser
#from langchain_core.runnables import RunnablePassthrough
logger = logging.getLogger(__name__)

class GenerationIntegrationModule:
    '''
    é›†æˆLLMä¸å›ç­”ç”Ÿæˆ
    '''
    def __init__(self,model_name:str,temperature:float = 0,max_tokens:int = 2048):
        '''
        åˆå§‹åŒ–
        '''
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.llm = None
        self._setup_llm()

    def _setup_llm(self):
        '''
        åŠ è½½llm
        '''
        logger.info(f"æ­£åœ¨åŠ è½½LLM : {self.model_name}")
        api_key = os.getenv("API_KEY")
        if not api_key:
            raise ValueError("è¯·å…ˆè®¾ç½®API_KEY")
        self.llm = ChatOpenAI(
            model = self.model_name,
            temperature = self.temperature,
            api_key = api_key,
            streaming = True,   #å…è®¸æµå¼è¾“å‡º
            base_url = os.getenv("BASE_URL"),
            max_tokens = self.max_tokens
        )
        logger.info(f"LLMåŠ è½½å®Œæˆ")
    
    def generate_basic_answer(self,query:str,context:List[Document])->str:
        '''
        æ ¹æ®æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡,è®©LLMç”ŸæˆåŸºç¡€å›ç­”
        Args:
            query:ç”¨æˆ·æŸ¥è¯¢
            context:æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
        Returns:
            LLMå›ç­”
        '''
        context = self._build_context(context)
        prompt = ChatPromptTemplate.from_template(
'''
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„çƒ¹é¥ªåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹é£Ÿè°±ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ç”¨æˆ·é—®é¢˜: {question}

ç›¸å…³é£Ÿè°±ä¿¡æ¯:
{context}

è¯·æä¾›è¯¦ç»†ã€å®ç”¨çš„å›ç­”ã€‚å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·è¯šå®è¯´æ˜ã€‚

å›ç­”:         
'''
        )
        #æ„å»ºé“¾
        chain = (
            prompt
            | self.llm
            | StrOutputParser()
        )
        response = chain.invoke({'question':query,'context':context})
        return response
    
    def _build_context(self,context:List[Document],max_length = 2000)->str:
        '''
        æ„å»ºä¸Šä¸‹æ–‡ï¼Œè´Ÿè´£æŠŠæ–‡æ¡£åˆ—è¡¨æ‹¼æˆä¸€ä¸ªæ•´ä½“å­—ç¬¦ä¸²
        Args:
            context: ä¸Šä¸‹æ–‡æ–‡æ¡£é›†åˆ
            max_length: æœ€å¤§é•¿åº¦
        Returns:
            æ ¼å¼åŒ–åçš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        '''
        if not context:
            return "æš‚æ— ä¸Šä¸‹æ–‡ä¿¡æ¯"
        #åˆå§‹åŒ–ä¸€ä¸ªå®¹å™¨ï¼Œå­˜æ”¾å¤„ç†åçš„ä¸Šä¸‹æ–‡ï¼ŒåŒæ—¶è®°å½•é•¿åº¦
        context_parts = []
        current_length = 0
        for i,doc in enumerate(context,1):  #ä»1å¼€å§‹è®¡æ•°

            #é¦–å…ˆå–å‡ºå…ƒæ•°æ®
            metadata_info = f"é£Ÿè°±{i}"
            if 'dish_name' in doc.metadata:
                metadata_info += f"{doc.metadata['dish_name']}"
            if 'category' in doc.metadata:
                metadata_info += f"| åˆ†ç±»ï¼š{doc.metadata['category']}"
            if 'difficulty' in doc.metadata:
                metadata_info += f"| éš¾æ˜“ç¨‹åº¦ï¼š{doc.metadata['difficulty']}"

            #æ„å»ºæ–‡æœ¬ï¼Œæ‹¼æ¥èµ·æ¥
            doc_context = f"{metadata_info} \n {doc.page_content}"

            #æ£€æŸ¥é•¿åº¦é™åˆ¶
            if current_length + len(doc_context) > max_length:
                break

            context_parts.append(doc_context)
            current_length += len(doc_context)
        return "\n" + '='*50 + '\n'+ '\n'.join(context_parts)  #æ¢è¡Œåï¼Œæ¯ä¸€è¡Œæ”¾ä¸€æ¡æ–‡æ¡£æ•°æ®

    def query_rewrite(self,query:str)->str:
        '''
        ç”±å¤§æ¨¡å‹æ¥åˆ¤æ–­æ˜¯å¦éœ€è¦é‡å†™è´¨é‡ä¸é«˜çš„query
        '''
        prompt = PromptTemplate.from_template(
'''
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æŸ¥è¯¢åˆ†æåŠ©æ‰‹ã€‚è¯·åˆ†æç”¨æˆ·çš„æŸ¥è¯¢ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦é‡å†™ä»¥æé«˜é£Ÿè°±æœç´¢æ•ˆæœã€‚

åŸå§‹æŸ¥è¯¢: {query}

åˆ†æè§„åˆ™ï¼š
1. **å…·ä½“æ˜ç¡®çš„æŸ¥è¯¢**ï¼ˆç›´æ¥è¿”å›åŸæŸ¥è¯¢ï¼‰ï¼š
   - åŒ…å«å…·ä½“èœå“åç§°ï¼šå¦‚"å®«ä¿é¸¡ä¸æ€ä¹ˆåš"ã€"çº¢çƒ§è‚‰çš„åˆ¶ä½œæ–¹æ³•"
   - æ˜ç¡®çš„åˆ¶ä½œè¯¢é—®ï¼šå¦‚"è›‹ç‚’é¥­éœ€è¦ä»€ä¹ˆé£Ÿæ"ã€"ç³–é†‹æ’éª¨çš„æ­¥éª¤"
   - å…·ä½“çš„çƒ¹é¥ªæŠ€å·§ï¼šå¦‚"å¦‚ä½•ç‚’èœä¸ç²˜é”…"ã€"æ€æ ·è°ƒåˆ¶ç³–é†‹æ±"

2. **æ¨¡ç³Šä¸æ¸…çš„æŸ¥è¯¢**ï¼ˆéœ€è¦é‡å†™ï¼‰ï¼š
   - è¿‡äºå®½æ³›ï¼šå¦‚"åšèœ"ã€"æœ‰ä»€ä¹ˆå¥½åƒçš„"ã€"æ¨èä¸ªèœ"
   - ç¼ºä¹å…·ä½“ä¿¡æ¯ï¼šå¦‚"å·èœ"ã€"ç´ èœ"ã€"ç®€å•çš„"
   - å£è¯­åŒ–è¡¨è¾¾ï¼šå¦‚"æƒ³åƒç‚¹ä»€ä¹ˆ"ã€"æœ‰é¥®å“æ¨èå—"

é‡å†™åŸåˆ™ï¼š
- ä¿æŒåŸæ„ä¸å˜
- å¢åŠ ç›¸å…³çƒ¹é¥ªæœ¯è¯­
- ä¼˜å…ˆæ¨èç®€å•æ˜“åšçš„
- ä¿æŒç®€æ´æ€§

ç¤ºä¾‹ï¼š
- "åšèœ" â†’ "ç®€å•æ˜“åšçš„å®¶å¸¸èœè°±"
- "æœ‰é¥®å“æ¨èå—" â†’ "ç®€å•é¥®å“åˆ¶ä½œæ–¹æ³•"
- "æ¨èä¸ªèœ" â†’ "ç®€å•å®¶å¸¸èœæ¨è"
- "å·èœ" â†’ "ç»å…¸å·èœèœè°±"
- "å®«ä¿é¸¡ä¸æ€ä¹ˆåš" â†’ "å®«ä¿é¸¡ä¸æ€ä¹ˆåš"ï¼ˆä¿æŒåŸæŸ¥è¯¢ï¼‰
- "çº¢çƒ§è‚‰éœ€è¦ä»€ä¹ˆé£Ÿæ" â†’ "çº¢çƒ§è‚‰éœ€è¦ä»€ä¹ˆé£Ÿæ"ï¼ˆä¿æŒåŸæŸ¥è¯¢ï¼‰

è¯·è¾“å‡ºæœ€ç»ˆæŸ¥è¯¢ï¼ˆå¦‚æœä¸éœ€è¦é‡å†™å°±è¿”å›åŸæŸ¥è¯¢ï¼‰:
'''
        )
        #æ„å»ºé“¾
        chain = (prompt | self.llm | StrOutputParser())

        response = chain.invoke({'query':query}).strip()  #å¾—åˆ°è¾“å‡ºå¹¶ç§»é™¤é¦–å°¾çš„ç©ºæ ¼

        if response != query:
            logger.info(f"æŸ¥è¯¢å·²æ”¹å†™ï¼š'{query}' -> '{response}'")
        else:
            logger.info(f"æŸ¥è¯¢æœªæ”¹å†™: '{query}")

        return response

    def query_router(self,query:str)->str:
        '''
        å®ç°å¤šæŸ¥è¯¢åŠŸèƒ½-æŸ¥è¯¢è·¯ç”±
        æ ¹æ®queryé€‰æ‹©ä¸åŒçš„å¤„ç†æ–¹å¼
        Args:
            query:æŸ¥è¯¢
        Returns:
            è·¯ç”±ç±»å‹ï¼š('list', 'detail', 'general')
        '''
        prompt = ChatPromptTemplate.from_template(
            '''
            æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œå°†å…¶åˆ†ç±»ä¸ºä»¥ä¸‹ä¸‰ç§ç±»å‹ä¹‹ä¸€ï¼š

1. 'list' - ç”¨æˆ·æƒ³è¦è·å–èœå“åˆ—è¡¨æˆ–æ¨èï¼Œåªéœ€è¦èœå
   ä¾‹å¦‚ï¼šæ¨èå‡ ä¸ªç´ èœã€æœ‰ä»€ä¹ˆå·èœã€ç»™æˆ‘3ä¸ªç®€å•çš„èœ

2. 'detail' - ç”¨æˆ·æƒ³è¦å…·ä½“çš„åˆ¶ä½œæ–¹æ³•æˆ–è¯¦ç»†ä¿¡æ¯
   ä¾‹å¦‚ï¼šå®«ä¿é¸¡ä¸æ€ä¹ˆåšã€åˆ¶ä½œæ­¥éª¤ã€éœ€è¦ä»€ä¹ˆé£Ÿæ

3. 'general' - å…¶ä»–ä¸€èˆ¬æ€§é—®é¢˜
   ä¾‹å¦‚ï¼šä»€ä¹ˆæ˜¯å·èœã€åˆ¶ä½œæŠ€å·§ã€è¥å…»ä»·å€¼

è¯·åªè¿”å›åˆ†ç±»ç»“æœï¼šlistã€detail æˆ– general

ç”¨æˆ·é—®é¢˜: {query}

åˆ†ç±»ç»“æœ:'''
        )

        chain = (prompt | self.llm | StrOutputParser())

        response = chain.invoke({'query':query}).strip().lower()

        #æ£€æŸ¥åˆ†ç±»æœ‰æ•ˆæ€§
        if response in ['list', 'detail', 'general']:
            return response
        else:
            return 'general'
        
    def generate_list_answer(self,query:str,context:List[Document])->str:
        '''
        list ç±»å‹çš„é—®é¢˜å›ç­”å™¨-é€‚åˆæ¨èç±»æŸ¥è¯¢ï¼Œæ¨èä¸€ç³»åˆ—èœå“
        Args:
            query:æé—®
            context:ä¸Šä¸‹æ–‡
        Returns:
            èœå“å›ç­”
        '''
        if not context:
            return "å¾ˆæŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„èœè°±"

        dishes = []
        for doc in context:
            dish_name = doc.metadata.get("dish_name","æœªçŸ¥èœå“")
            #å»é‡
            if dish_name not in dishes:
                dishes.append(dish_name)
        
        #æ„é€ å›ç­”
        if len(dishes) == 1:
            return f"ä¸ºä½ æ¨èæ­¤èœå“ï¼š{dishes[0]} \n"
        elif len(dishes) <= 3:
            return f"ä¸ºä½ æ¨èä»¥ä¸‹èœå“ : \n" + "\n".join( [f"{i},{name}" for i,name in enumerate(dishes)] )
        else:
            return f"ä¸ºä½ æ¨èä»¥ä¸‹èœå“ : \n" + "\n".join( [f"{i},{name}" for i,name in enumerate(dishes[:3])] ) + f"\n\n è¿˜æœ‰å…¶ä»–{len(dishes) - 3} é“èœå“å¯ä¾›é€‰æ‹©"
                
    def generate_detail_answer(self,query:str,context:List[Document]):
        '''
        detailç±»å‹çš„å›ç­”å™¨
        Args:
            query:æŸ¥è¯¢
            context:ä¸Šä¸‹æ–‡
        Returns:
            LLMå›ç­”
        '''
        context = self._build_context(context)
        
        prompt = ChatPromptTemplate.from_template(
        '''ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„çƒ¹é¥ªå¯¼å¸ˆã€‚è¯·æ ¹æ®é£Ÿè°±ä¿¡æ¯ï¼Œä¸ºç”¨æˆ·æä¾›è¯¦ç»†çš„åˆ†æ­¥éª¤æŒ‡å¯¼ã€‚

ç”¨æˆ·é—®é¢˜: {question}

ç›¸å…³é£Ÿè°±ä¿¡æ¯:
{context}

è¯·çµæ´»ç»„ç»‡å›ç­”ï¼Œå»ºè®®åŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼ˆå¯æ ¹æ®å®é™…å†…å®¹è°ƒæ•´ï¼‰ï¼š

## ğŸ¥˜ èœå“ä»‹ç»
[ç®€è¦ä»‹ç»èœå“ç‰¹ç‚¹å’Œéš¾åº¦]

## ğŸ›’ æ‰€éœ€é£Ÿæ
[åˆ—å‡ºä¸»è¦é£Ÿæå’Œç”¨é‡]

## ğŸ‘¨â€ğŸ³ åˆ¶ä½œæ­¥éª¤
[è¯¦ç»†çš„åˆ†æ­¥éª¤è¯´æ˜ï¼Œæ¯æ­¥åŒ…å«å…·ä½“æ“ä½œå’Œå¤§æ¦‚æ‰€éœ€æ—¶é—´]

## ğŸ’¡ åˆ¶ä½œæŠ€å·§
[ä»…åœ¨æœ‰å®ç”¨æŠ€å·§æ—¶åŒ…å«ã€‚å¦‚æœåŸæ–‡çš„"é™„åŠ å†…å®¹"ä¸çƒ¹é¥ªæ— å…³æˆ–ä¸ºç©ºï¼Œå¯ä»¥åŸºäºåˆ¶ä½œæ­¥éª¤æ€»ç»“å…³é”®è¦ç‚¹ï¼Œæˆ–è€…å®Œå…¨çœç•¥æ­¤éƒ¨åˆ†]

æ³¨æ„ï¼š
- æ ¹æ®å®é™…å†…å®¹çµæ´»è°ƒæ•´ç»“æ„
- ä¸è¦å¼ºè¡Œå¡«å……æ— å…³å†…å®¹
- é‡ç‚¹çªå‡ºå®ç”¨æ€§å’Œå¯æ“ä½œæ€§

å›ç­”:'''
        )
        chain = (prompt | self.llm | StrOutputParser())
        input = {'question':query,'context':context}

        response = chain.invoke(input)
        return response

    def generate_general_answer(self,query:str,context:List[Document]):
        '''
        generalç±»å‹çš„ç”Ÿæˆå™¨
        Args:
            query:æŸ¥è¯¢
            context:ä¸Šä¸‹æ–‡
        '''
        context = self._build_context(context)
        prompt = ChatPromptTemplate.from_template(
            '''
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„çƒ¹é¥ªåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹é£Ÿè°±ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ç”¨æˆ·é—®é¢˜: {question}

ç›¸å…³é£Ÿè°±ä¿¡æ¯:
{context}

è¯·æä¾›è¯¦ç»†ã€å®ç”¨çš„å›ç­”ã€‚å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·è¯šå®è¯´æ˜ã€‚

å›ç­”:'''
        )
        chain = (prompt | self.llm | StrOutputParser())

        input = {'question':query,'context':context}

        response = chain.invoke(input)
        return response
