'''
ç”Ÿäº§é›†æˆæ¨¡å—
'''
import logging
import os 
from langchain_openai import ChatOpenAI
from typing import List
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate,PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain.schema import AIMessage, HumanMessage, SystemMessage
#from langchain_core.runnables import RunnablePassthrough
logger = logging.getLogger(__name__)

class GenerationIntegrationModule:
    '''
    é›†æˆLLMä¸å›ç­”ç”Ÿæˆ
    '''
    def __init__(self,model_name:str,temperature:float = 0,max_tokens:int = 2048,history_window_size:int = 8):
        '''
        åˆå§‹åŒ–
        '''
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.history_window_size = 8
        self.llm = None
        self._setup_llm()


    def _setup_llm(self):
        '''
        åŠ è½½llm
        '''
        logger.info(f"æ­£åœ¨åŠ è½½LLM : {self.model_name}")
        api_key = os.getenv("API_KEY")
        if not api_key:
            raise ValueError("è¯·å…ˆè®¾ç½®API_KEY")
        self.llm = ChatOpenAI(
            model = self.model_name,
            temperature = self.temperature,
            api_key = api_key,
            streaming = True,   #å…è®¸æµå¼è¾“å‡º
            base_url = os.getenv("BASE_URL"),
            max_tokens = self.max_tokens
        )
        logger.info(f"LLMåŠ è½½å®Œæˆ")
    
    def generate_chitchat_answer(self,query:str,context:List[Document],history = None)->str:
        '''
        é—²èŠç±»é—®é¢˜ï¼ˆä¸éœ€è¦æ£€ç´¢ï¼‰ç›´æ¥ç”¨ LLM å›ç­”
        '''
        messages = [SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªäº²åˆ‡çš„ç¾é£ŸåŠ©æ‰‹ï¼Œå¯ä»¥å‹å¥½åœ°ä¸ç”¨æˆ·é—²èŠã€‚")]
        if history:
            for msg in history[-self.history_window_size:]:
                if msg["role"] == "user":
                    messages.append(HumanMessage(content=msg["content"]))
                elif msg["role"] == "assistant":
                    messages.append(AIMessage(content=msg["content"]))
        messages.append(HumanMessage(content=query))

        response = self.llm.invoke(messages)
        return response.content
    
    def _build_context(self,context:List[Document],max_length = 2000)->str:
        '''
        æ„å»ºä¸Šä¸‹æ–‡ï¼Œè´Ÿè´£æŠŠæ–‡æ¡£åˆ—è¡¨æ‹¼æˆä¸€ä¸ªæ•´ä½“å­—ç¬¦ä¸²
        Args:
            context: ä¸Šä¸‹æ–‡æ–‡æ¡£é›†åˆ
            max_length: æœ€å¤§é•¿åº¦
        Returns:
            æ ¼å¼åŒ–åçš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        '''
        if not context:
            return "æš‚æ— ä¸Šä¸‹æ–‡ä¿¡æ¯"
        #åˆå§‹åŒ–ä¸€ä¸ªå®¹å™¨ï¼Œå­˜æ”¾å¤„ç†åçš„ä¸Šä¸‹æ–‡ï¼ŒåŒæ—¶è®°å½•é•¿åº¦
        context_parts = []
        current_length = 0
        for i,doc in enumerate(context,1):  #ä»1å¼€å§‹è®¡æ•°

            #é¦–å…ˆå–å‡ºå…ƒæ•°æ®
            metadata_info = f"é£Ÿè°±{i}"
            if 'dish_name' in doc.metadata:
                metadata_info += f"{doc.metadata['dish_name']}"
            if 'category' in doc.metadata:
                metadata_info += f"| åˆ†ç±»ï¼š{doc.metadata['category']}"
            if 'difficulty' in doc.metadata:
                metadata_info += f"| éš¾æ˜“ç¨‹åº¦ï¼š{doc.metadata['difficulty']}"

            #æ„å»ºæ–‡æœ¬ï¼Œæ‹¼æ¥èµ·æ¥
            doc_context = f"{metadata_info} \n {doc.page_content}"

            #æ£€æŸ¥é•¿åº¦é™åˆ¶
            if current_length + len(doc_context) > max_length:
                break

            context_parts.append(doc_context)
            current_length += len(doc_context)
        return "\n" + '='*50 + '\n'+ '\n'.join(context_parts)  #æ¢è¡Œåï¼Œæ¯ä¸€è¡Œæ”¾ä¸€æ¡æ–‡æ¡£æ•°æ®

    def query_rewrite(self,query:str,history = None)->str:
        '''
        ç”±å¤§æ¨¡å‹æ¥åˆ¤æ–­æ˜¯å¦éœ€è¦é‡å†™è´¨é‡ä¸é«˜çš„query
        '''
        prompt = PromptTemplate.from_template(
        '''
        ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æŸ¥è¯¢é‡å†™åŠ©æ‰‹ï¼Œè´Ÿè´£å°†ç”¨æˆ·è¾“å…¥çš„æŸ¥è¯¢åœ¨å¿…è¦æ—¶é‡å†™ä¸ºæ›´é€‚åˆèœè°±æ£€ç´¢çš„è¡¨è¾¾ã€‚

        === å½“å‰å¯¹è¯å†å²ï¼ˆç”¨äºåˆ¤æ–­ä¸Šä¸‹æ–‡æŒ‡ä»£ï¼‰ ===
        {history}

        === å½“å‰ç”¨æˆ·æŸ¥è¯¢ ===
        {query}

        === åˆ¤æ–­ä¸é‡å†™è§„åˆ™ ===

        1. âœ… **å…·ä½“æ˜ç¡®çš„æŸ¥è¯¢ï¼ˆä¸é‡å†™ï¼‰**
        - åŒ…å«å…·ä½“èœå“åç§°ï¼šå¦‚â€œå®«ä¿é¸¡ä¸æ€ä¹ˆåšâ€ã€â€œçº¢çƒ§è‚‰çš„åšæ³•â€
        - æ˜ç¡®æ­¥éª¤/æŠ€å·§æé—®ï¼šå¦‚â€œç³–é†‹æ’éª¨ç”¨ä»€ä¹ˆè°ƒæ–™â€ã€â€œå¦‚ä½•ç‚’èœä¸ç²˜é”…â€

        2. âŒ **æ¨¡ç³Šæˆ–å®½æ³›çš„æŸ¥è¯¢ï¼ˆåº”é‡å†™ï¼‰**
        - ä¸å«èœåï¼šå¦‚â€œåšèœâ€ã€â€œæ¨èä¸ªèœâ€ã€â€œç®€å•çš„â€
        - æ— å…·ä½“ç›®æ ‡ï¼šå¦‚â€œæƒ³åƒç‚¹ä»€ä¹ˆâ€ã€â€œæ¥ç‚¹ç´ çš„â€

        3. ğŸ” **æŒ‡ä»£å‹æŸ¥è¯¢ï¼ˆéœ€ä¸Šä¸‹æ–‡é‡å†™ï¼‰**
        - åŒ…å«â€œè¿™ä¸ªâ€ã€â€œå®ƒâ€ã€â€œç¬¬ä¸€ä¸ªâ€ç­‰æŒ‡ä»£è¯
        - å¦‚æœå†å²ä¸­å‡ºç°äº†æ¨èèœå“åˆ—è¡¨ï¼ˆå¦‚â€œæ¨èäº†æ°´ç…®é±¼ã€çº¢çƒ§è‚‰â€ï¼‰ï¼Œåˆ™ç”¨å¯¹åº”èœåæ›¿æ¢æŒ‡ä»£è¯
        - è‹¥å†å²ä¸ºç©ºæˆ–èœåæ— æ³•åˆ¤æ–­ï¼Œä¿ç•™åŸæŸ¥è¯¢ä¸åšä¿®æ”¹

        === é‡å†™åŸåˆ™ ===
        - å¢å¼ºè¯­ä¹‰æ¸…æ™°åº¦ï¼Œæ–¹ä¾¿èœè°±ç³»ç»Ÿç†è§£
        - ä¿ç•™ç”¨æˆ·åŸæ„ï¼Œä¸å¼•å…¥ä¸ç›¸å…³ä¿¡æ¯
        - ä¼˜å…ˆæ¨èå®¶å¸¸èœã€æ˜“åšèœï¼Œé£æ ¼æ¸…æ™°

        === ç¤ºä¾‹ ===
        - â€œåšèœâ€ â†’ â€œç®€å•æ˜“åšçš„å®¶å¸¸èœè°±â€
        - â€œæœ‰é¥®å“æ¨èå—â€ â†’ â€œç®€å•é¥®å“åˆ¶ä½œæ–¹æ³•â€
        - â€œå·èœâ€ â†’ â€œç»å…¸å·èœèœè°±â€
        - â€œå®«ä¿é¸¡ä¸æ€ä¹ˆåšâ€ â†’ â€œå®«ä¿é¸¡ä¸æ€ä¹ˆåšâ€
        - â€œç¬¬ä¸€ä¸ªæ€ä¹ˆåšâ€ + ä¸Šæ–‡æåˆ°â€œæ°´ç…®é±¼ã€çº¢çƒ§è‚‰â€ â†’ â€œæ°´ç…®é±¼æ€ä¹ˆåšâ€
        - â€œå®ƒéœ€è¦ä»€ä¹ˆè°ƒæ–™â€ + ä¸Šæ–‡æåˆ°â€œæ¨èäº†éº»è¾£é¦™é”…â€ â†’ â€œéº»è¾£é¦™é”…éœ€è¦ä»€ä¹ˆè°ƒæ–™â€

        === è¾“å‡ºè¦æ±‚ ===
        è¯·è¾“å‡ºæœ€ç»ˆç”¨äºèœè°±æ£€ç´¢çš„æŸ¥è¯¢å†…å®¹ï¼ˆå¦‚æ— éœ€æ”¹å†™åˆ™åŸæ ·è¿”å›ï¼‰ï¼š
        '''
        )
        #æ„å»ºé“¾
        chain = (prompt | self.llm | StrOutputParser())
        history = self._format_history(history)
        response = chain.invoke({'query':query,'history':history}).strip()  #å¾—åˆ°è¾“å‡ºå¹¶ç§»é™¤é¦–å°¾çš„ç©ºæ ¼

        if response != query:
            logger.info(f"æŸ¥è¯¢å·²æ”¹å†™ï¼š'{query}' -> '{response}'")
        else:
            logger.info(f"æŸ¥è¯¢æœªæ”¹å†™: '{query}")

        return response

    def _format_history(self,history: List[dict]) -> str:
        '''
        å°†å¯¹è¯å†å²æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²
        '''
        if not history:
            return "ï¼ˆæ— ï¼‰"
        formatted = ""
        for msg in history[-4:]:  # æœ€å¤šä¿ç•™æœ€è¿‘ 4 æ¡
            role = "ç”¨æˆ·" if msg["role"] == "user" else "ChefGPT"
            formatted += f"{role}ï¼š{msg['content']}\n"
        return formatted.strip()

    def query_router(self,query:str)->str:
        '''
        å®ç°å¤šæŸ¥è¯¢åŠŸèƒ½-æŸ¥è¯¢è·¯ç”±
        æ ¹æ®queryé€‰æ‹©ä¸åŒçš„å¤„ç†æ–¹å¼
        Args:
            query:æŸ¥è¯¢
        Returns:
            è·¯ç”±ç±»å‹ï¼š('list', 'detail', 'general','chitchat)
        '''
        prompt = ChatPromptTemplate.from_template(
            '''
            æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œå°†å…¶åˆ†ç±»ä¸ºä»¥ä¸‹ä¸‰ç§ç±»å‹ä¹‹ä¸€ï¼š

        1. 'list' - ç”¨æˆ·æƒ³è¦è·å–èœå“åˆ—è¡¨æˆ–æ¨èï¼Œåªéœ€è¦èœå
        ä¾‹å¦‚ï¼šæ¨èå‡ ä¸ªç´ èœã€æœ‰ä»€ä¹ˆå·èœã€ç»™æˆ‘3ä¸ªç®€å•çš„èœ

        2. 'detail' - ç”¨æˆ·æƒ³è¦å…·ä½“çš„åˆ¶ä½œæ–¹æ³•æˆ–è¯¦ç»†ä¿¡æ¯
        ä¾‹å¦‚ï¼šå®«ä¿é¸¡ä¸æ€ä¹ˆåšã€åˆ¶ä½œæ­¥éª¤ã€éœ€è¦ä»€ä¹ˆé£Ÿæ

        3. 'general' - å…¶ä»–ä¸€èˆ¬æ€§çŸ¥è¯†é—®é¢˜
        ä¾‹å¦‚ï¼šä»€ä¹ˆæ˜¯å·èœã€åˆ¶ä½œæŠ€å·§ã€è¥å…»ä»·å€¼

        4. 'chitchat' - é—²èŠé—®å€™ç±»é—®é¢˜ï¼ˆå¦‚â€œä½ å¥½â€â€œè°¢è°¢â€â€œä½ æ˜¯è°â€ï¼‰

        è¯·åªè¿”å›åˆ†ç±»ç»“æœï¼šlistã€detailã€ generalæˆ–è€…chitchat

        ç”¨æˆ·é—®é¢˜: {query}

        åˆ†ç±»ç»“æœ:'''
        )

        chain = (prompt | self.llm | StrOutputParser())

        response = chain.invoke({'query':query}).strip().lower()

        #æ£€æŸ¥åˆ†ç±»æœ‰æ•ˆæ€§
        if response in ['list', 'detail', 'general','chitchat']:
            return response
        else:
            return 'general'
        
    def generate_list_answer(self,query:str,context:List[Document])->str:
        '''
        list ç±»å‹çš„é—®é¢˜å›ç­”å™¨-é€‚åˆæ¨èç±»æŸ¥è¯¢ï¼Œæ¨èä¸€ç³»åˆ—èœå“
        Args:
            query:æé—®
            context:ä¸Šä¸‹æ–‡
        Returns:
            èœå“å›ç­”
        '''
        if not context:
            return "å¾ˆæŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„èœè°±"

        dishes = []
        for doc in context:
            dish_name = doc.metadata.get("dish_name","æœªçŸ¥èœå“")
            #å»é‡
            if dish_name not in dishes:
                dishes.append(dish_name)
        
        #æ„é€ å›ç­”
        if len(dishes) == 1:
            return f"ä¸ºä½ æ¨èæ­¤èœå“ï¼š{dishes[0]} \n"
        elif len(dishes) <= 3:
            return f"ä¸ºä½ æ¨èä»¥ä¸‹èœå“ : \n" + "\n".join( [f"{i},{name}" for i,name in enumerate(dishes)] )
        else:
            return f"ä¸ºä½ æ¨èä»¥ä¸‹èœå“ : \n" + "\n".join( [f"{i},{name}" for i,name in enumerate(dishes[:3])] ) + f"\n\n è¿˜æœ‰å…¶ä»–{len(dishes) - 3} é“èœå“å¯ä¾›é€‰æ‹©"
                
    def generate_detail_answer(self,query:str,context:List[Document],history:List[dict] = None):
        '''
        detailç±»å‹çš„å›ç­”å™¨
        Args:
            query:æŸ¥è¯¢
            context:ä¸Šä¸‹æ–‡
            history:å¯¹è¯å†å²
        Returns:
            LLMå›ç­”
        '''
        #æ‹¼æ¥ä¸Šä¸‹æ–‡
        context = self._build_context(context) 
        
        system_prompt = '''ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„çƒ¹é¥ªå¯¼å¸ˆã€‚è¯·æ ¹æ®é£Ÿè°±ä¿¡æ¯ï¼Œä¸ºç”¨æˆ·æä¾›è¯¦ç»†çš„åˆ†æ­¥éª¤æŒ‡å¯¼ã€‚

        ç”¨æˆ·é—®é¢˜: {question}

        ç›¸å…³é£Ÿè°±ä¿¡æ¯:
        {context}

        è¯·çµæ´»ç»„ç»‡å›ç­”ï¼Œå»ºè®®åŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼ˆå¯æ ¹æ®å®é™…å†…å®¹è°ƒæ•´ï¼‰ï¼š

        ## ğŸ¥˜ èœå“ä»‹ç»
        [ç®€è¦ä»‹ç»èœå“ç‰¹ç‚¹å’Œéš¾åº¦]

        ## ğŸ›’ æ‰€éœ€é£Ÿæ
        [åˆ—å‡ºä¸»è¦é£Ÿæå’Œç”¨é‡]

        ## ğŸ‘¨â€ğŸ³ åˆ¶ä½œæ­¥éª¤
        [è¯¦ç»†çš„åˆ†æ­¥éª¤è¯´æ˜ï¼Œæ¯æ­¥åŒ…å«å…·ä½“æ“ä½œå’Œå¤§æ¦‚æ‰€éœ€æ—¶é—´]

        ## ğŸ’¡ åˆ¶ä½œæŠ€å·§
        [ä»…åœ¨æœ‰å®ç”¨æŠ€å·§æ—¶åŒ…å«ã€‚å¦‚æœåŸæ–‡çš„"é™„åŠ å†…å®¹"ä¸çƒ¹é¥ªæ— å…³æˆ–ä¸ºç©ºï¼Œå¯ä»¥åŸºäºåˆ¶ä½œæ­¥éª¤æ€»ç»“å…³é”®è¦ç‚¹ï¼Œæˆ–è€…å®Œå…¨çœç•¥æ­¤éƒ¨åˆ†]

        æ³¨æ„ï¼š
        - æ ¹æ®å®é™…å†…å®¹çµæ´»è°ƒæ•´ç»“æ„
        - ä¸è¦å¼ºè¡Œå¡«å……æ— å…³å†…å®¹
        - é‡ç‚¹çªå‡ºå®ç”¨æ€§å’Œå¯æ“ä½œæ€§

        å›ç­”:'''
        #æ„é€ å†å²æ¶ˆæ¯

        #æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
        message = [SystemMessage(content = system_prompt)]
        if history:
            for msg in history[-self.history_window_size:]:
                if msg['role'] == 'user':
                    message.append(HumanMessage(content=msg['content']))
                elif msg['role'] == 'assistant':
                    message.append(AIMessage(content=msg['content']))

        #æ„é€ æœ¬è½®å¯¹è¯
        current_input = f"ç”¨æˆ·é—®é¢˜ï¼š{query}\n\nç›¸å…³é£Ÿè°±ä¿¡æ¯ä¸º:{context}"
        #æ·»åŠ è¿›å†å²æ¶ˆæ¯
        message.append(HumanMessage(content=current_input))

        #è·å–å›ç­”
        response = self.llm.invoke(message)
        return response.content

    def generate_general_answer(self,query:str,context:List[Document],history:List[dict] = None):
        '''
        generalç±»å‹çš„ç”Ÿæˆå™¨
        Args:
            query:æŸ¥è¯¢
            context:ä¸Šä¸‹æ–‡
        '''
        context = self._build_context(context)
        system_prompt = '''
        ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„çƒ¹é¥ªåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹é£Ÿè°±ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

        ç”¨æˆ·é—®é¢˜: {question}

        ç›¸å…³é£Ÿè°±ä¿¡æ¯:
        {context}

        è¯·æä¾›è¯¦ç»†ã€å®ç”¨çš„å›ç­”ã€‚å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·è¯šå®è¯´æ˜ã€‚

        å›ç­”:'''

        #æ„é€ å†å²æ¶ˆæ¯

        #æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
        message = [SystemMessage(content = system_prompt)]
        if history:
            for msg in history[-self.history_window_size:]:
                if msg['role'] == 'user':
                    message.append(HumanMessage(content=msg['content']))
                elif msg['role'] == 'assistant':
                    message.append(AIMessage(content=msg['content']))

        #æ„é€ æœ¬è½®å¯¹è¯
        current_input = f"ç”¨æˆ·é—®é¢˜ï¼š{query}\n\nç›¸å…³é£Ÿè°±ä¿¡æ¯ä¸º:{context}"
        #æ·»åŠ è¿›å†å²æ¶ˆæ¯
        message.append(HumanMessage(content=current_input))

        #è·å–å›ç­”
        response = self.llm.invoke(message)
        return response.content
