'''
RAGé¡¹ç›®ä¸»ç¨‹åº
'''
import os
import sys
import logging
from pathlib import Path
from typing import List

#æ·»åŠ æ¨¡å—æœç´¢è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from dotenv import load_dotenv
from config import RAGConfig, DEFAULT_CONFIG  #åˆšå¼€å§‹æ— æ³•è¯†åˆ«ï¼Œæ·»åŠ äº†ä¸€ä¸ªç©ºçš„__init__.pyæ–‡ä»¶è§£å†³äº†
from rag_modules import (DataPreparationModule,GenerationIntegrationModule,IndexConstructionModule,RetrievalOptimizationModule)


#åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

#é…ç½®æ—¥å¿— è®¾ç½®æ—¥å¿—çš„æœ€ä½çº§åˆ«ã€è¾“å‡ºæ ¼å¼
logging.basicConfig(
    level = logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class RAGSystem:
    '''
    RAGä¸»ç³»ç»Ÿ
    '''
    def __init__(self,config:RAGConfig = None):
        '''
        åˆå§‹åŒ–RAGç³»ç»Ÿ
        '''
        self.config = config or DEFAULT_CONFIG  #å¦‚æœæ²¡æœ‰configæ–‡ä»¶å°±ç”¨é»˜è®¤çš„
        #åˆå§‹åŒ–å››ä¸ªæ¨¡å—
        self.data_module = None
        self.generation_module = None
        self.index_module = None
        self.retrieval_module = None

        #æ£€æŸ¥ä¸‹æ•°æ®è·¯å¾„
        if not Path(self.config.data_path).exists():
            raise FileNotFoundError(f"æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {self.config.data_path}")
    
        #æ£€æŸ¥ä¸‹API
        if not os.getenv("API_KEY"):
            raise ValueError("è¯·è®¾ç½®API!!")
        
    def initial_system(self):
        '''
        åˆå§‹åŒ–æ‰€æœ‰æ¨¡å—
        '''
        logger.info("æ­£åœ¨åŠ è½½æ•°æ®æ¨¡å—.....")
        self.data_module = DataPreparationModule(self.config.data_path)
        
        logger.info("æ­£åœ¨åŠ è½½ç´¢å¼•æ¨¡å—.....")
        self.index_module = IndexConstructionModule(self.config.embedding_model,
                                                    self.config.vector_index_path)

        logger.info("æ­£åœ¨åŠ è½½é›†æˆæ¨¡å—.....")
        self.generation_module = GenerationIntegrationModule(self.config.model_name,
                                                            self.config.temperature,
                                                            self.config.max_tokens,self.config.history_window_size)
        logger.info("...ç³»ç»Ÿå·²ç»åŠ è½½å®Œæˆ...")

    
    def build_knowledge_base(self):
        '''
        æ„å»ºç´¢å¼•å‘é‡ç­‰ä¸€ç³»åˆ—æ“ä½œ
        '''
        #å…ˆå°è¯•åŠ è½½ç´¢å¼•
        vectorstore = self.index_module.load_index()
        
        if vectorstore is not None:

            print("æˆåŠŸåŠ è½½å·²ä¿å­˜çš„å‘é‡ç´¢å¼•ï¼")

            #ç”±äºåœ¨æ£€ç´¢ä¼˜åŒ–é˜¶æ®µè¿˜éœ€è¦åˆ©ç”¨åˆ°æ–‡æ¡£

            #åŠ è½½çˆ¶æ–‡æ¡£
            print("æ­£åœ¨åŠ è½½é£Ÿè°±æ–‡æ¡£")
            documents = self.data_module.load_documents()

            #åŠ è½½å­æ–‡æ¡£
            print("æ­£åœ¨åˆ’åˆ†å­æ–‡æ¡£")
            chunks = self.data_module.chunk_documents()
        else:

            print("æœªæ£€æµ‹åˆ°å·²æœ‰çš„å‘é‡ç´¢å¼•ï¼Œé‡æ–°å»ºç«‹...")

            #åŠ è½½çˆ¶æ–‡æ¡£
            print("æ­£åœ¨åŠ è½½é£Ÿè°±æ–‡æ¡£")
            documents = self.data_module.load_documents()

            #åŠ è½½å­æ–‡æ¡£
            print("æ­£åœ¨åˆ’åˆ†å­æ–‡æ¡£")
            chunks = self.data_module.chunk_documents()

            #æ„å»ºç´¢å¼•
            print("æ­£åœ¨æ„å»ºç´¢å¼•")
            self.index_module.set_up_embedding()
            vectorstore = self.index_module.build_vector_index(chunks)

            #ä¿å­˜ç´¢å¼•
            print("æ­£åœ¨ä¿å­˜ç´¢å¼•")
            self.index_module.save_index()
        
        print("...æ­£åœ¨å‡†å¤‡æ£€ç´¢ä¼˜åŒ–æ¨¡å—...")
        self.retrieval_module = RetrievalOptimizationModule(vectorstore,chunks)
        logger.info("RetrievalOptimizationModule åˆå§‹åŒ–å®Œæˆ")

    def ask_question(self,question:str,stream:bool = False,history:List[dict] = None):
        '''
        å›ç­”ç”¨æˆ·é—®é¢˜çš„å‡½æ•°
        Args:
            question:ç”¨æˆ·çš„é—®é¢˜
            stream:æ˜¯å¦æ˜¯æµå¼è¾“å‡º
            history:å›ç­”ä¸Šä¸‹æ–‡
        Returns:
            LLMå›ç­”
        '''

        #å…ˆæ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦æ„å»ºå®Œæ¯•
        if not all([self.retrieval_module,self.generation_module]):
            raise ValueError("è¯·å…ˆæ„å»ºçŸ¥è¯†åº“")
        
        print(f"ç”¨æˆ·é—®é¢˜ï¼š {question} \n")

        #ä¸ºxxbæ·»åŠ å½©è›‹
        if question.strip().lower() == 'kyy':
            print(
            "\nğŸŒ¸ äº²çˆ±çš„ KYY ğŸŒ¸\n"
            "åœ¨è¿™ä¸ªçŸ¥è¯†ç³»ç»Ÿä¸­ï¼Œæœ‰ä¸€ä¸ªå½©è›‹åªä¸ºä½ è€Œç”Ÿã€‚\n\n"
            "ğŸ’– ä½ æ˜¯ç‰¹åˆ«çš„ã€å¯çˆ±çš„ã€å€¼å¾—è¢«ä¸–ç•Œæ¸©æŸ”ä»¥å¾…çš„äººã€‚\n"
            "ğŸ½ï¸ æ— è®ºä½ æƒ³åƒä»€ä¹ˆï¼Œæˆ‘éƒ½ä¼šå°½åŠ›å¸®ä½ æ‰¾åˆ°æœ€æ£’çš„åšæ³•ã€‚\n"
            "â˜€ï¸ æ„¿ä½ æ¯å¤©éƒ½æœ‰å¥½å¿ƒæƒ…ï¼Œå¥½èƒƒå£ï¼Œè¿˜æœ‰ä¸€ç‚¹ç‚¹å°å¹¸è¿ï½\n\n"
            "ğŸ’Œ â€”â€” æ¥è‡ªä½ çš„ä¸“å±ç¾é£Ÿ AI\n")
            return None

        #æ²¡æœ‰å†å²å°±åˆå§‹åŒ–
        history = history or []

        #æŸ¥è¯¢è·¯ç”±
        router_type = self.generation_module.query_router(question)
        #å¦‚æœæ˜¯é—²èŠçš„è¯
        if router_type == 'chitchat':
            print("é—²èŠç±»é—®é¢˜ï¼Œä¸è§¦å‘RAGæ£€ç´¢\n")
            return self.generation_module.generate_chitchat_answer(question, history)
        #æ ¹æ®ç±»å‹æ¥åˆ¤æ–­æ˜¯å¦éœ€è¦é‡å†™query
        if router_type == 'list':
            print("listç±»å‹é—®é¢˜ï¼Œä¸éœ€è¦é‡å†™\n")
            query = question
        else:
            query = self.generation_module.query_rewrite(question,history)
            print(f"é—®é¢˜å·²ç»è‡ªåŠ¨æ™ºèƒ½é‡å†™ä¸º:{query}\n")
        
        #åˆ©ç”¨æ··åˆæ£€ç´¢è¿›è¡Œæ£€ç´¢
        relevant_chunks = self.retrieval_module.hybrid_search(query)

        if relevant_chunks:
            print(f"æ‰¾åˆ°äº†{len(relevant_chunks)}ä¸ªç›¸å…³æ–‡æ¡£\n")
        else:
            print("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–‡æ¡£\n")

        for i, doc in enumerate(relevant_chunks):
            dish_name = doc.metadata.get("dish_name", "æœªçŸ¥èœå“")
            source = doc.metadata.get("source", "æœªçŸ¥è·¯å¾„")
            chunk_index = doc.metadata.get("chunk_index", "æ— ")
            chunk_content = doc.page_content.strip().replace('\n', ' ')[:200]  # åªæ˜¾ç¤ºå‰200ä¸ªå­—ç¬¦ï¼Œé¿å…å¤ªé•¿

            print(f"[{i+1}] èœåï¼š{dish_name} | chunk_indexï¼š{chunk_index} | æ¥æºï¼š{source}")
            print(f"    ğŸ” å†…å®¹ç‰‡æ®µï¼š{chunk_content}")
            print("-" * 80)
       
        
        #å…ˆæ‰¾åˆ°ç›¸å…³çš„çˆ¶æ–‡æ¡£ç”¨äºå›ç­”é—®é¢˜
        relevant_docs = self.data_module.get_parent_document(relevant_chunks)

        #å±•ç¤ºä¸‹æ‰¾åˆ°çš„èœå
        doc_names = []

        print(f"\nğŸ” æ‰¾åˆ°äº† {len(relevant_docs)} ä¸ªç›¸å…³æ–‡æ¡£ï¼Œå¯¹åº”èœå“å¦‚ä¸‹ï¼š\n")

        for i, doc in enumerate(relevant_docs):
            dish_name = doc.metadata.get("dish_name", "æœªçŸ¥èœå“")
            source = doc.metadata.get("source", "æœªçŸ¥è·¯å¾„")
            chunk_index = doc.metadata.get("chunk_index", "æ— ")
            
            doc_names.append(dish_name)
            
            print(f"[{i+1}] èœåï¼š{dish_name} | chunk_indexï¼š{chunk_index} | æ¥æºï¼š{source}")

        print("\nğŸ“‹ èœå“æ±‡æ€»ï¼š")
        print("ï¼Œ".join(doc_names))

        #åˆ†ç±»å›ç­”é—®é¢˜
        if router_type == 'list':
            #è¿”å›å›ç­”å™¨
            return self.generation_module.generate_list_answer(query,relevant_docs)
        elif router_type == 'detail':
            return self.generation_module.generate_detail_answer(query,relevant_docs,history)
        else:
            return self.generation_module.generate_general_answer(query,relevant_docs,history)
        
    def run_interactive(self):
        '''
        æ„å»ºä¸€ä¸ªäº¤äº’å¼ç³»ç»Ÿ
        '''
        print("=" * 60)
        print("ğŸ³  æ¬¢è¿æ¥åˆ° çŸ¥å‘³å°å¨ ï¼ˆChefGPTï¼‰ ğŸ³".center(60))
        print("=" * 60)
        print("ğŸ¤– åŸºäº RAG æŠ€æœ¯çš„æ™ºèƒ½èœè°±é—®ç­”ç³»ç»Ÿï¼ŒåŠ©æ‚¨è½»æ¾æŒå¨ï¼".center(60))
        print("=" * 60)

        #åˆå§‹åŒ–ç³»ç»Ÿ
        self.initial_system()
        print("ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ\n")

        #æ„å»ºçŸ¥è¯†åº“
        self.build_knowledge_base()

        #åˆå§‹åŒ–å¯¹è¯å†å²
        history = []

        print("\näº¤äº’å¼é—®ç­” (è¾“å…¥'é€€å‡º'ç»“æŸ):")
        
        while True:
            try:
                user_input = input("\næ‚¨çš„é—®é¢˜: ").strip()
                if user_input.lower() in [ 'é€€å‡º','exit','quit']:
                    print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ ChefGPTï¼Œå†è§ï¼")
                    break

                #è·å–å›ç­”
                answer = self.ask_question(user_input, stream=False,history = history)
                #è·³è¿‡å½©è›‹
                if not  answer:
                    continue

                #æ·»åŠ ç”¨æˆ·ä¿¡æ¯åˆ°å†å²
                history.append({'role':'user','content':user_input})
                #æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯åˆ°å†å²
                history.append({'role':'assistant','content':answer})

                print(f"{answer}\n")
            except KeyboardInterrupt:
                break
            except Exception as e:
                print(f"å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {e}\n")

def main():
    '''
    ä¸»å‡½æ•°å…¥å£
    '''
    try:
        rag = RAGSystem()
        rag.run_interactive()
    except Exception as e:
        logger.error(f"ç³»ç»Ÿè¿è¡Œå‡ºé”™: {e}")
        print(f"å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {e}\n")

if __name__ == "__main__":
    main()
    





